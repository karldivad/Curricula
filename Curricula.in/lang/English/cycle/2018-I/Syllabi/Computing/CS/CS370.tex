\begin{syllabus}

\course{CS3700. Big Data}{Obligatorio}{CS3700} % Common.pm

\begin{justification}
Nowadays, knowing scalable approaches to processing and storing large volumes of information (terabytes, petabytes and even exabytes) is fundamental in computer science courses. Every day, every hour, every minute generates a large amount of information which needs to be processed, stored, analyzed.
\end{justification}

\begin{goals}
\item That the student is able to create parallel applications to process large volumes of information
\item That the student is able to compare the alternatives for the processing of big data
\item That the student is able to propose architectures for a scalable application
\end{goals}

\begin{outcomes}{V1}
    \item \ShowOutcome{a}{2} 
    \item \ShowOutcome{b}{2} 
    \item \ShowOutcome{i}{2} 
    \item \ShowOutcome{j}{2} 
\end{outcomes}

\begin{competences}{V1}
    \item \ShowCompetence{C2}{a}
    \item \ShowCompetence{C4}{b}
    \item \ShowCompetence{C16}{i} 
    \item \ShowCompetence{CS2}{i} 
    \item \ShowCompetence{CS3}{j} 
    \item \ShowCompetence{CS6}{j} 
\end{competences}

\begin{unit}{Introducci√≥n a Big Data}{}{coulouris}{15}{C2, C4}
\begin{topics}%
        \item Overview on Cloud Computing 
        \item Distributed File System Overview%
        \item Overview of the MapReduce programming model%
\end{topics}
\begin{learningoutcomes}%
        \item Explain the concept of Cloud Computing from the point of view of Big Data[\Familiarity] %
        \item Explain the concept of Distributed File System [\Familiarity] %
        \item Explain the concept of the MapReduce programming model[\Familiarity] %
\end{learningoutcomes}%
\end{unit}

\begin{unit}{Hadoop}{}{dongarra, buyya}{15}{C2, C4}
\begin{topics}
    \item Hadoop overview.
    \item History.
    \item Hadoop Structure.
    \item HDFS, Hadoop Distributed File System.
    \item Programming Model MapReduce
\end{topics}
\begin{learningoutcomes}
      \item Understand and explain the Hadoop suite [\Familiarity]
      \item Implement solutions using the MapReduce programming model. [\Usage]
      \item Understand how data is saved in the HDFS. [\Familiarity] %
\end{learningoutcomes}
\end{unit}

\begin{unit}{Procesamiento de Grafos en larga escala}{}{graphlab, pregel, giraph}{10}{C16}
\begin{topics}
    \item Pregel: A System for Large-scale Graph Processing.
    \item Distributed GraphLab: A Framework for Machine Learning and Data Mining in the Cloud.
    \item Apache Giraph is an iterative graph processing system built for high scalability.
\end{topics}
\begin{learningoutcomes}
      \item Understand and explain the architecture of the Pregel project. [\Familiarity]
	  \item Understand the GraphLab project architecture. [\Familiarity]
	  \item Understand the architecture of the Giraph project.  [\Familiarity]
	  \item Implement solutions using Pregel, GraphLab or Giraph. [\Usage]
\end{learningoutcomes}
\end{unit}

\begin{coursebibliography}
\bibfile{Computing/CS/CS370}
\end{coursebibliography}

\end{syllabus}
