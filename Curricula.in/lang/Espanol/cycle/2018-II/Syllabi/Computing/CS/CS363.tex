\begin{syllabus}

\course{CS363. Aprendizaje de Máquina}{Obligatorio}{CS363} % Common.pm

\begin{justification}

El tema central del curso es entender los principios de aprendizaje de máquina para el descubrimiento de patrones, buscando aplicar los conceptos en soluciones prácticas. Se estudiarán técnicas de aprendizaje automático, construcción de algoritmos y evaluación para el análisis predictivo en grandes volúmenes de información. El curso cubre estrategias de aprendizaje automático como regresión, clasificación y clustering; modelos inteligentes como árboles de decisión, redes neuronales y SVM; métodos de pre-procesamiento de información y reducción de dimensionalidad. Finalmente se analizarán tendencias de aprendizaje de máquina como deep learning.
\end{justification}

\begin{goals}
\item El objetivo central de este curso es estudiar distintas técnicas de aprendizaje de máquina que permitan la búsqueda de patrones 
      dentro de la información para un mejor uso de la misma y, en consecuencia, proponer soluciones más eficientes en problemas de ciencia de datos.
\item Entender las técnicas de aprendizaje de máquinas y cómo están relacionadas a estadística y análisis de datos.
\item Estudiar algoritmos computacionales de búsqueda de patrones en conjuntos de datos.
\item Aplicar técnicas de aprendizaje supervisado y no supervisado en el reconocimiento de patrones y realización de decisiones y predicciones con ejemplos prácticos.
\item Evaluar los distintos clasificadores a través de técnicas que no sólo evalúen la precisión, sino también, el desempeño del clasificador.
\item Preparar los datos para obtener resultados más confiables.
\item Estudiar la influencia que las técnicas de aprendizaje de máquina y minería de datos vienen teniendo sobre la sociedad.
\end{goals}

\begin{outcomes}
\item \ShowOutcome{a}{2}
\item \ShowOutcome{i}{2}
\end{outcomes}

\begin{competences}
    \item \ShowCompetence{C1,C20}{a,i}
\end{competences}

\begin{unit}{Introducción}{}{witten2016}{6}{C1,C20}
\begin{topics}
      \item Introducción y objetivos del curso. Terminología básica. ¿Big data?, Necesidad de aprendizaje de máquina, Ambientes para el aprendizaje de máquina, Minería de Datos, Casos de Estudio. 
      \item Paradigmas de aprendizaje de máquina, Clasificación, Clustering. Ejemplos de aplicación, Herramientas de ML, Weka, Información de entrada.
   \end{topics}

\end{unit}

\begin{unit}{Regresión}{}{Bishop2006, duda2012, Theodoridis2008}{14}{C1,C20}
\begin{topics}
      \item Regresión lineal para la predicción de un valor real basado en determinados valores de entrada, función modelo y costo, método de gradiente descendiente para aprendizaje, aplicaciones de regresión lineal. Regresión lineal simple y múltiple.
    \end{topics}

\end{unit}

\begin{unit}{Clasificación}{}{Bishop2006, duda2012, Theodoridis2008}{6}{C1,C20}
\begin{topics}
      \item Introducción. Conceptos básicos. Algoritmos de clasificación: KNN, Regresión logística. Regiones de decisión. Clasificación multiclase.
      \item El problema del overfitting. Regularización: principios, efectos, aplicación a regresión lineal y regresión logística.
      \item Redes Neuronales. Introducción y representación. Propagación hacia adelante. Arquitecturas de redes. Unidades de salida múltiple.
      \item Redes Neuronales. Aprendizaje. Función de costo. Algoritmo de retropropagación.
      \item SVM. Clasificación por máquinas de vectores de soporte, uso de kernels, aplicaciones de SVM
      \item Árboles de decisión. Entradas con variables continuas y discretas. Entropía y ganancia de información.

\end{topics}

\end{unit}

\begin{unit}{Evaluación del aprendizaje}{}{Bishop2006, duda2012, Theodoridis2008}{16}{C1,C20}
\begin{topics}
      \item Introducción. Bias vs. varianza. Clasificación con conjuntos de entrenamiento, prueba y validación. Validación cruzada, Comparación de esquemas de Minería de Datos. Matriz de confusión. Análisis ROC.
   \end{topics}

\end{unit}

\begin{unit}{Aprendizaje por ensamble}{}{Bishop2006, duda2012, Theodoridis2008}{16}{C1,C20}
\begin{topics}
      \item Clasificación por esquemas de ensamble. Adaboost. Random Forest. Esquemas de boosting, bagging y votación.
   \end{topics}

\end{unit}

\begin{unit}{Aprendizaje no supervisado}{}{Bishop2006, duda2012, Theodoridis2008}{16}{C1,C20}
\begin{topics}
      \item Introducción. Contenido: Introducción al análisis de clustering, algoritmo de K-medias, K-medianas, Ventajas y desventajas, optimización de k-medias.
   \end{topics}

\end{unit}

\begin{unit}{Otros enfoques y aplicaciones de aprendizaje de máquina}{}{Bishop2006, duda2012, Theodoridis2008, Murphy2012}{16}{C1,C20}
\begin{topics}
      \item Técnicas de reducción de dimensionalidad y selección de características. Análisis de componentes principales PCA.
      \item Detección de anomalías. Estimación de densidad. Distribuciones gaussianas univariadas y multivariadas. Importancia de una evaluación real cuantitativa.
      \item Aprendizaje semi-supervisado. Aprendizaje activo. Aprendizaje por refuerzo. Aprendizaje profundo. Direcciones Futuras.
   \end{topics}
\end{unit}



\begin{coursebibliography}
\bibfile{Computing/CS/CS363}
\end{coursebibliography}

\end{syllabus}
