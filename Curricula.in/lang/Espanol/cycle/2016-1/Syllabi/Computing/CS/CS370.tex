\begin{syllabus}

\course{CS370. Big Data}{Obligatorio}{CS370}

\begin{justification}
En la actualidad conocer enfoques escalables para procesar y almacenar grande volumenes de información (terabytes, petabytes e inclusive exabytes) es fundamental en cursos de ciencia de la computación. Cada dia, cada hora, cada minuto se genera gran cantidad de información la cual necesitá ser procesada, almacenada, analisada.
\end{justification}

\begin{goals}
\item Que el alumno sea capaz de crear aplicaciones paralelas para procesar grandes volumenes de información.
\item Que el alumno sea capaz de comparar las alternativas para el procesamiento de big data.
\item Que el alumno sea capaz de proponer arquitecturas para una aplicación escalable.
\end{goals}

\begin{outcomes}
    \item \ShowOutcome{a}{2} 
    \item \ShowOutcome{b}{2} 
    \item \ShowOutcome{i}{2} 
    \item \ShowOutcome{j}{2} 
\end{outcomes}

\begin{competences}
    \item \ShowCompetence{C2}{a}
    \item \ShowCompetence{C4}{b}
    \item \ShowCompetence{C16}{i} 
    \item \ShowCompetence{CS2}{i} 
    \item \ShowCompetence{CS3}{j} 
    \item \ShowCompetence{CS6}{j} 
\end{competences}

\begin{unit}{}{Introducción a Big Data}{coulouris}{15}{C2, C4}
\begin{topics}%
        \item 
        \item Visión global sobre Cloud Computing
        \item Visión global sobre Sistema de Archivos Distribuidos%
        \item Visión global sobre el modelo de programación MapReduce%
\end{topics}
\begin{learningoutcomes}%
        \item Explicar el concepto de Cloud Computing desde el punto de vista de Big Data[\Familiarity] %
        \item Explicar el concepto de los Sistema de Archivos Distribuidos [\Familiarity] %
        \item Explicar el concepto del modelo de programación MapReduce[\Familiarity] %
\end{learningoutcomes}%
\end{unit}

\begin{unit}{}{Hadoop}{dongarra, buyya}{15}{C2, C4}
\begin{topics}
    \item Visión global de Hadoop.
    \item Historia.
    \item Estructura de Hadoop.
    \item HDFS, Hadoop Distributed File System.
    \item Modelo de Programación MapReduce
\end{topics}
\begin{learningoutcomes}
      \item Entender y explicar la suite de Hadoop. [\Familiarity]
      \item Implementar soluciones usando el modelo de programación MapReduce. [\Usage]
      \item Entender la forma como se guardan los datos en el HDFS. [\Familiarity] %
\end{learningoutcomes}
\end{unit}

\begin{unit}{}{Procesamiento de Grafos en larga escala}{graphlab, pregel, giraph}{10}{C16}
\begin{topics}
    \item Pregel: A System for Large-scale Graph Processing.
    \item Distributed GraphLab: A Framework for Machine Learning and Data Mining in the Cloud.
    \item Apache Giraph is an iterative graph processing system built for high scalability.
\end{topics}
\begin{learningoutcomes}
      \item Entender y explicar la arquitectura del proyecto Pregel. [\Familiarity]
	  \item Entender la arquitectura del proyecto GraphLab. [\Familiarity]
	  \item Entender la arquitectura del proyecto Giraph.  [\Familiarity]
	  \item Implementar soluciones usando Pregel, GraphLab o Giraph. [\Usage]
\end{learningoutcomes}
\end{unit}



\begin{coursebibliography}
\bibfile{Computing/CS/CS370}
\end{coursebibliography}

\end{syllabus}
