\begin{syllabus}

\course{CS3P01. Computación Paralela y Distribuída}{Obligatorio}{CS3P01}
% Source file: ../Curricula.in/lang/Espanol/cycle/2020-I/Syllabi/Computing/CS/CS3P1.tex

\begin{justification}
La última década ha traído un crecimiento explosivo en computación con multiprocesadores, incluyendo 
los procesadores de varios núcleos y centros de datos distribuidos. Como resultado, la computación 
paralela y distribuida se ha convertido de ser un tema ampliamente electivo para ser uno de los principales componentes
en la malla estudios en ciencia de la computación de pregrado. Tanto la computación paralela como la distribuida implica 
la ejecución simultánea de múltiples procesos, cuyas operaciones tienen el potencial para 
intercalar de manera compleja. La computación paralela y distribuida construye sobre cimientos en muchas 
áreas, incluyendo la comprensión de los conceptos fundamentales de los sistemas, tales como: concurrencia 
y ejecución en paralelo, consistencia en el estado/manipulación de la memoria, y latencia. La 
comunicación y la coordinación entre los procesos tiene sus cimientos en el paso de mensajes y modelos de 
memoria compartida de la computación y conceptos algorítmicos como atomicidad, el consenso y espera condicional. 
El logro de aceleración en la práctica requiere una comprensión de algoritmos paralelos, estrategias para la 
descomposición problema, arquitectura de sistemas, estrategias de implementación y análisis de 
rendimiento. Los sistemas distribuidos destacan los problemas de la seguridad y tolerancia a 
fallos, hacen hincapié en el mantenimiento del estado replicado e introducen problemas adicionales en el campo de 
las redes de computadoras.
\end{justification}

\begin{goals}
\item Que el alumno sea capaz de crear aplicaciones paralelas de mediana complejidad aprovechando eficientemente máquinas con múltiples núcleos.
\item Que el alumno sea capaz de comparar aplicaciones secuenciales y paralelas.
\item Que el alumno sea capaz de convertir, cuando la situación lo amerite, aplicaciones secuenciales a paralelas de forma eficiente.
\end{goals}

\begin{outcomes}{V1}
    \item \ShowOutcome{a}{2} 
    \item \ShowOutcome{b}{2}
    \item \ShowOutcome{c}{2}
    \item \ShowOutcome{g}{2} 
\end{outcomes}

\begin{outcomes}{V2}
    \item \ShowOutcome{1}{2} 
    \item \ShowOutcome{2}{2}
    \item \ShowOutcome{6}{2} 
\end{outcomes}

\begin{competences}{V1}
    \item \ShowCompetence{C3}{b,g}
    \item \ShowCompetence{C4}{b,c}
    \item \ShowCompetence{CS1}{a}
    \item \ShowCompetence{CS4}{a}
\end{competences}

\begin{competences}{V2}
    \item \ShowCompetence{C3}{2}
    \item \ShowCompetence{C4}{2}
    \item \ShowCompetence{CS1}{1,6}
    \item \ShowCompetence{CS4}{1,6}
\end{competences}

\begin{unit}{\PDParallelismFundamentals}{}{peterpacheco,matloff,quinn}{18}{C2}
\begin{topics}%
    \item \PDParallelismFundamentalsTopicMultiple
    \item \PDParallelismFundamentalsTopicGoals
    \item \PDParallelismFundamentalsTopicParallelism
    \item \PDParallelismFundamentalsTopicProgramming
\end{topics}    
\begin{learningoutcomes}%
    \item \PDParallelismFundamentalsLODistinguishUsing~[\Familiarity] %
    \item \PDParallelismFundamentalsLODistinguishMultiple~[\Familiarity] %
    \item \PDParallelismFundamentalsLODistinguishData~[\Familiarity] %
\end{learningoutcomes}%
\end{unit}

\begin{unit}{\PDParallelArchitecture}{}{peterpacheco,wenmei,sanders}{12}{C4}
\begin{topics}%
    \item \PDParallelArchitectureTopicMulticore
    \item \PDParallelArchitectureTopicShared
    \item \PDParallelArchitectureTopicSymmetric
    \item \PDParallelArchitectureTopicSimd
    \item \PDParallelArchitectureTopicGpu
    \item \PDParallelArchitectureTopicFlynns
    \item \PDParallelArchitectureTopicInstruction
    \item \PDParallelArchitectureTopicMemory
    \item \PDParallelArchitectureTopicTopologies
\end{topics}
\begin{learningoutcomes}%
    \item \PDParallelArchitectureLOExplainTheShared~[\Assessment] %
    \item \PDParallelArchitectureLODescribeTheAndKey~[\Assessment] %
    \item \PDParallelArchitectureLOCharacterizeTheTasks~[\Usage] %
    \item \PDParallelArchitectureLODescribeTheLimitationsVs~[\Usage] %
    \item \PDParallelArchitectureLOExplainTheEach~[\Usage] %
    \item \PDParallelArchitectureLODescribeTheMaintaining~[\Familiarity] %
    \item \PDParallelArchitectureLODescribeTheChallenges~[\Familiarity] %
\end{learningoutcomes}%
\end{unit}

\begin{unit}{\PDParallelDecomposition}{}{peterpacheco,matloff,quinn}{18}{C16}
\begin{topics}%
    \item \PDParallelDecompositionTopicNeed
    \item \PDParallelDecompositionTopicIndependence
    \item \PDParallelDecompositionTopicBasic
    \item \PDParallelDecompositionTopicTask
    \item \PDParallelDecompositionTopicData
    \item \PDParallelDecompositionTopicActors
\end{topics}
\begin{learningoutcomes}%
    \item \PDParallelDecompositionLOExplainWhyNecessary~[\Usage] %
    \item \PDParallelDecompositionLOIdentifyOpportunities~[\Familiarity] %
    \item \PDParallelDecompositionLOWriteAScalable~[\Usage] %
    \item \PDParallelDecompositionLOParallelize~[\Usage] %
    \item \PDParallelDecompositionLOParallelizeAn~[\Usage] %
    \item \PDParallelDecompositionLOWriteAActors~[\Usage] %
\end{learningoutcomes}%
\end{unit}

\begin{unit}{\PDCommunicationandCoordination}{}{peterpacheco,matloff,quinn}{18}{C16}
\begin{topics}%
    \item \PDCommunicationandCoordinationTopicShared
    \item \PDCommunicationandCoordinationTopicConsistency
    \item \PDCommunicationandCoordinationTopicMessage
    \item \PDCommunicationandCoordinationTopicAtomicity
    \item \PDCommunicationandCoordinationTopicConsensus
    \item \PDCommunicationandCoordinationTopicConditional
\end{topics}
\begin{learningoutcomes}%
    \item \PDCommunicationandCoordinationLOUseMutual~[\Usage] %
    \item \PDCommunicationandCoordinationLOGiveAn~[\Familiarity] %
    \item \PDCommunicationandCoordinationLOGiveAnA~[\Usage] %
    \item \PDCommunicationandCoordinationLOExplainWhenMulticast~[\Familiarity] %
    \item \PDCommunicationandCoordinationLOWriteACorrectly~[\Usage] %
    \item \PDCommunicationandCoordinationLOGiveAnAWhich~[\Familiarity] %
    \item \PDCommunicationandCoordinationLOUseSemaphores~[\Usage] %
\end{learningoutcomes}%
\end{unit}

\begin{unit}{\PDParallelAlgorithmsAnalysisandProgramming}{}{matloff,quinn}{18}{CS2}
\begin{topics}%
    \item \PDParallelAlgorithmsAnalysisandProgrammingTopicCritical
    \item \PDParallelAlgorithmsAnalysisandProgrammingTopicSpeed
    \item \PDParallelAlgorithmsAnalysisandProgrammingTopicNaturally
    \item \PDParallelAlgorithmsAnalysisandProgrammingTopicParallel
    \item \PDParallelAlgorithmsAnalysisandProgrammingTopicParallelGraph
    \item \PDParallelAlgorithmsAnalysisandProgrammingTopicParallelMatrix
    \item \PDParallelAlgorithmsAnalysisandProgrammingTopicProducer
    \item \PDParallelAlgorithmsAnalysisandProgrammingTopicExamples
\end{topics}
\begin{learningoutcomes}%
        \item \PDParallelAlgorithmsAnalysisandProgrammingLODefineCritical~[\Familiarity] %
        \item \PDParallelAlgorithmsAnalysisandProgrammingLOComputeTheSpan~[\Usage] %
        \item \PDParallelAlgorithmsAnalysisandProgrammingLODefineSpeed~[\Familiarity] %
        \item \PDParallelAlgorithmsAnalysisandProgrammingLOIdentifyIndependent~[\Usage] %
        \item \PDParallelAlgorithmsAnalysisandProgrammingLOCharacterizeFeatures~[\Familiarity] %
        \item \PDParallelAlgorithmsAnalysisandProgrammingLOImplementAAnd~[\Usage] %
        \item \PDParallelAlgorithmsAnalysisandProgrammingLODecompose~[\Usage] %
        \item \PDParallelAlgorithmsAnalysisandProgrammingLOProvideAn~[\Usage] %
        \item \PDParallelAlgorithmsAnalysisandProgrammingLOGiveExamplesWhere~[\Usage] %
        \item \PDParallelAlgorithmsAnalysisandProgrammingLOImplementAAlgorithm~[\Usage] %
        \item \PDParallelAlgorithmsAnalysisandProgrammingLOIdentifyIssuesIn~[\Usage] %
\end{learningoutcomes}%
\end{unit}

\begin{unit}{\PDParallelPerformance}{}{peterpacheco,matloff,wenmei,sanders}{18}{CS3}
\begin{topics}%
    \item \PDParallelPerformanceTopicLoad
    \item \PDParallelPerformanceTopicPerformance
    \item \PDParallelPerformanceTopicScheduling
    \item \PDParallelPerformanceTopicEvaluating
    \item \PDParallelPerformanceTopicData
    \item \PDParallelPerformanceTopicPower
\end{topics}
\begin{learningoutcomes}%
    \item \PDParallelPerformanceLODetect~[\Usage] %
    \item \PDParallelPerformanceLOCalculateThe~[\Usage] %
    \item \PDParallelPerformanceLODescribeHowLayout~[\Familiarity] %
    \item \PDParallelPerformanceLODetectAnd~[\Usage] %
    \item \PDParallelPerformanceLOExplainTheScheduling~[\Familiarity] %
    \item \PDParallelPerformanceLOExplainPerformance~[\Familiarity] %
    \item \PDParallelPerformanceLOExplainTheTrade~[\Familiarity] %
\end{learningoutcomes}%
\end{unit}

\begin{coursebibliography}
\bibfile{Computing/CS/CS3P1}
\end{coursebibliography}

\end{syllabus}
